{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4T20ZC09clVNR1Q5LE7Ry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/DataExtraction/blob/main/Otros/Bajar_Youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bajar el MP4"
      ],
      "metadata": {
        "id": "gWjIFV-wkTsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVkKgHEycU4i",
        "outputId": "b413bac8-9bf2-4b97-ab1a-7c5b238490c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.6.9-py3-none-any.whl.metadata (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.6.9-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUezFXEIcKK9",
        "outputId": "da7ac1e7-1c6c-49c5-9957-87b1c4d528c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=p_S6NIEfu-U\n",
            "[youtube] p_S6NIEfu-U: Downloading webpage\n",
            "[youtube] p_S6NIEfu-U: Downloading tv client config\n",
            "[youtube] p_S6NIEfu-U: Downloading player 9fe2e06e-main\n",
            "[youtube] p_S6NIEfu-U: Downloading tv player API JSON\n",
            "[youtube] p_S6NIEfu-U: Downloading ios player API JSON\n",
            "[youtube] p_S6NIEfu-U: Downloading m3u8 information\n",
            "[info] p_S6NIEfu-U: Downloading 1 format(s): 18\n",
            "[download] Destination: ¿Qué es la AGI？ ¿Cuándo llegará la INTELIGENCIA ARTIFICIAL GENERAL？ [p_S6NIEfu-U].mp4\n",
            "[download] 100% of   80.13MiB in 00:00:06 at 11.53MiB/s  \n"
          ]
        }
      ],
      "source": [
        "import yt_dlp\n",
        "\n",
        "def download(link):\n",
        "    ydl_opts = {'format': 'best'}\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([link])\n",
        "\n",
        "link = 'https://www.youtube.com/watch?v=p_S6NIEfu-U'\n",
        "download(link)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MP4 to MP3"
      ],
      "metadata": {
        "id": "C-CJH0_igu5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "sMy0FNZ7gxqU",
        "outputId": "4448823e-2098-4269-acf5-b27a02172bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Load your video\n",
        "video = VideoFileClip(\"/content/¿Qué es la AGI？ ¿Cuándo llegará la INTELIGENCIA ARTIFICIAL GENERAL？ [p_S6NIEfu-U].mp4\")\n",
        "\n",
        "# Extract audio and write to MP3\n",
        "video.audio.write_audiofile(\"audio.mp3\")\n"
      ],
      "metadata": {
        "id": "R9gHTLF9hCM4",
        "outputId": "9ec9d12f-f8c5-449d-ab1b-13d532ef3e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "id": "mTn7HwYthhu3",
        "outputId": "2602b2e4-c799-4274-b969-04c1a9ac46a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/800.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=60ca822cb68f1e5a8d472c84204b7b6f60fd50244197926dc08fb3072ef93531\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Cargar el modelo (puede ser \"tiny\", \"base\", \"small\", \"medium\", \"large\")\n",
        "modelo = whisper.load_model(\"base\")  # Elegí \"small\" si querés más precisión\n",
        "\n",
        "# Transcribir el MP3\n",
        "resultado = modelo.transcribe(\"/content/audio.mp3\", language=\"es\", fp16=False)\n",
        "\n",
        "# Mostrar el texto\n",
        "print(resultado[\"text\"])"
      ],
      "metadata": {
        "id": "7L9ZBbTChj9U",
        "outputId": "85111f8a-6360-40ff-fe00-91435d356572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 52.8MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " La inteligencia artificial cada vez es más potente. Y si hace cinco años apenas contábamos solo con sistemas capaces de leer o valbusear textos, a día de hoy contamos con sistemas capaces de resolver problemas de olimpiadas matemáticas, de posicionarse en los ranking mundiales de competiciones de programación o creando instantáneamente piezas audiovisuales indiferenciables de la realidad. Todos lo estamos sintiendo, ¿verdad? Ese vertigo, ese sentimiento de que lo único que podemos tener claro sobre el futuro es que va a ser muy diferente al presente que estamos viviendo ahora. Que las predicciones de que la IA lo iba a cambiar todos se están volviendo realidad. Sentís la AI. Que un humano hace, pero sólo mejor. Hay una probabilidad, la IA es que ha pasado muy pronto. Hay una probabilidad que ha pasado mucho más. Pero mi posición es que la probabilidad de la IA lo ha pasado en el día, es muy bien que hay que ser muy bien. Ya o del antoque en 2025 mucho del debate de la inteligencia artificial se va a entrar justamente en este concepto. La inteligencia artificial general, la IA, pero exactamente qué es cómo se define. ¿Y qué tan cerca estamos de conseguirla? Hoy analizamos por primera vez en este canal y que sirva esto como testimonio de los tiempos que estamos viviendo el concepto de IA. El ser humano tiene tendencia a verse como el centro del universo y cuando hablamos de inteligencia no iba a ser menos. Si viajamos a 1956 en la historia conferencia de Dardmuth donde se forjó el concepto de inteligencia artificial, la propuesta inicial ya indicaba que sería un intento de averiguar cómo lograr que las máquinas usaran el lenguaje, formaran abstractiones y conceptos y resolvieran tipos de problemas que actualmente estaban reservados para los humanos. Una propuesta muy ambiciosa, puesto que para lograr esto se pusieron de plazo dos meses. Este texto que di origen al campo de la inteligencia artificial fue muy premonitorio estableciendo un objetivo claro, máquinas capaces de ser tan inteligente como nosotros. Pero claro, esto no es un objetivo ambiguo, al final una calculadora, pues es una máquina que puede hacer cálculos matemáticos a un nivel similar o incluso superior que nosotros, con más velocidad y precisión. ¿Ceñifica eso que una calculadora es una AI? No, aquí la clave está en la G de AI, que nos habla de la inteligencia general. Y es que recordaréis que ya en 2017 cuando os definí por primera vez en uno de los primeros vídeos del canal que era la inteligencia artificial os dije lo siguiente. Al final es cierto que nosotros los humanos ponemos a destacar tanto como una maquinita en tareas concretas, pero a, somos muy buenos en un rango amplio de tareas, muy variado. Siendo incluso capaces de aprender nuevas habilidades para adaptarnos. Y es en esta generalidad en la capacidad de aprender y ejecutar una gran diversidad de tareas, lo que se persigue cuando hablamos de inteligencia artificial general. Inteligencias artificiales que sean tan capaces en un rango de tareas tan amplio como nosotros o humanos. Por lo tanto, para empezar a organizar un poco las cosas, si podemos decir que una inteligencia artificial será más general que otra, si es más capaz a la hora de resolver una tarea y además si esa tarea cubre un mayor rango de habilidades. Visto así, en estas dos dimensiones podemos decir que Gpt4 es más general que Gpt2, por su mejor capacidad de generar texto y por que haciendo esto, cubre un rango mayor de habilidades. La ducirco, digo de programación, escribir poemas todo esto. Y claro, viste así, pues nosotros somos un tipo de inteligencia más general que Gpt4. Teniendo este esquema como guía, pues podemos ver que el día que la inteligencia artificial llegue más o menos a este punto, es decir, mismo desempeñón sus capacidades en un rango tan amplio como todo lo que nosotros podamos hacer, que entonces ahí estaremos hablando de una agir. ¿Y qué tan cerca está la ia de lograr esto? Pues veamos, hemos dicho que una de las dimensiones es su desempeño. Y a nivel de capacidades desde el boom del DiplarNin y las redes neuronales en 2012, ya sabéis que la inteligencia artificial no ha parado de mejorar. Hace menos de 10 años evaluábamos a la ia por su capacidad del R, reconocer imágenes o resolver problemas sencillos de matemáticas. Tareas para las que poco a poco la ia alcanzó nuestro nivel. Así que le pusimos tareas matificiles. Provevas de conocimiento general lectura en múltiples idiomas con peticiones de matemática. Y de nuevo, a un ritmo más rápido que antes volvió alcanzar nuestras capacidades. De hecho, a día de hoy modelos como Gpt4 o Cloud o Gemini se evaluan sobre tareas no paraías, si notarías académicas y profesionales para humanos, logrando nuevamente cada vez un mayor desempeño. En cuestión de 15 años, la ia pasado de aprender a hablar y escribir, a sacarse múltiples carreras universitarias a la vez. Así que en capacidades, cada vez nos moemos más rápido en esta dirección. Y en generalidad, aquí es donde creo que está lo más interesante. Porque de nuevo, hace no tanto tiempo, los modelos de día eran sistemas de redes neuronales que se entrenaban para hacer muy bien una única tarea. Y sí, la sea muy bien, pero era eso, una sola tarea. Una ia entrenada para hacerte resúmenes de texto, pues no era capaz de escribirte bien un poema. Pero luego llegó esta idea de los modelos fundacionales como los GptS. Donde ahora un mismo modelo, pues te podías hacer un resumen, traducir, responder preguntas, y decir, un único modelo resolviendo múltiples tareas, inteligencias artificiales más generales. Pero es que luego esto le sumamos también la multimodalidad. La capacidad de que la ia pueda procesar fonte de información de diferente naturaleza, texto, imágenes, audio, acciones de robots, haciendo por tanto a los modelos más versátiles y capaces de resolver tareas en múltiples dominios, modelos más generales. Y la última tendencia que tenemos que sumar ahora es el actual paradigma del test time compute. Donde los modelos pueden dedicar tiempo de computación a pensar más en la solución de un problema, planteando opciones y estrategias alternativas y diseñando durante la inferencia soluciones creativas a problemas nuevos, demostrando una creatividad nunca antes vista que ahora nos permite utilizar estos modelos ya entrenados para resolver problemas que antes la ia no podía resolver. En cuestión de una década, modelos más capaces y más generales. Y casi parecería que pocos más avances tienen que dar para poder llegar a ese objetivo de la agí. Dices a Malmante en una de sus últimas declaraciones que están confiados en que saben cómo construir la agí. Y claro, estando todo esto resuelto, pues uno podría pensar que lo más difícil ya queda atrás, pero realmente lo más difícil viene ahora. Y es saber diferenciar que hay tanto de real y cuánto hay de marketing. Porque los incentivos para empresas privadas de decir que saben cómo construir una agí son elevados. De existir una tecnología de tal calibre, pues sería de un altísimo valor económico para la empresa que lo posea. Y siendo así, quién no invertiría en una empresa que dice saber cómo implementarla. De hecho, incluso casos más curiosos en toda esta batalla comercial por la ia general, en el acuerdo de alianza entre OpenAI y Microsoft, donde ya sabéis que uno ofrece acceso al otro a grandes cantidades de recursos, computacionales, mientras que el otro le da acceso a sus investigaciones y tecnologías más avanzadas. Pero, ojito porque no todas las tecnologías desarrolladas por OpenAI van a ser dadas a Microsoft y es que en el acuerdo lo especifica muy bien. El acuerdo quedará invalidado si esa tecnología es una agí. Y claro, siendo esto así, hay muchos incentivos por parte de muchas empresas por declararse con guistadores de la AI, lo cual no obliga a definirlo con un poquito más de exactitud. Y aquí aparece una de las empresas que fue pionera a la hora de ponerse como objetivo construir una agí. En tiempos en los que decir esto en alto era motivo de burla en la Academia. Hablamos por supuesto del laboratorio Deep Mind, que en uno de sus papers del año pasado de 2024 definía con la siguiente tabla los diferentes niveles de sistema inteligentes con los que clasificar a una agí. Para ello, se basaban en estas dos dimensiones que hemos comentado antes. La capacidad de la AI a la hora de resolver una tarea, a medida en este caso por el presentil, que ocuparía esa AI frente al resto de la humanidad, y luego por su grado de generalidad. Aquí clasificado entre inteligencias artificiales, específicas e inteligencias artificiales generales. Puesto así, por ejemplo, en el nivel 1 nos encontramos a aquellas AI que tienen capacidades iguales o un poquito mejor que la de un humano no especializado. Es decir, aquellas inteligencias artificiales cuyo nivel de desempeño fuera, pues el tuyo o el mío para aquellas tareas de las cuales nosotros no somos especialistas. Yo, por ejemplo, no se escribir un Hikeu, se la idea general tres frasesitas, pues puedo chapurrear. Ese sería el nivel 1. Y lo interesante es que en este nivel es donde aparecían sistemas como ChatGPT o Gemini. Catalogadas como ellas generales emergentes. Es decir, pueden hacer un amplio rango de tareas al igual que un humano no especializado. Pero luego esto continúa con más niveles. Competente, si supera la mitad de la población adulta, experto si supera el 90% virtuoso en el 99% y 100% al nivel super humano. Y para cada uno de estos niveles pues sí tenemos ejemplos de ellas estrechas, cuyo desempeño se enfoca solo en tareas concretas. Donde sabemos que a día de hoy contamos con sistemas que juegarán a la G3s mejor que humanos o capazes de predecir la forma de la proteína, que yo, por ejemplo, no soy capaz. Ok. Sin embargo lo interesante lo encontramos en la otra columna, en la de la ia generalista. No se ha conseguido, no se ha conseguido y no se ha conseguido. Claro, esto te hace un año, pero y si tuvieramos que actualizarla a día de hoy. Acaso sistemas como ChatGPT no son capaces de hacer ahora tareas que lo graban hace un año, pero a un nivel superior que el de la mitad de la población o incluso mejor que el 90% de la población a nivel experto. De hecho hemos visto que modelos como O3 en competiciones de programación pues consigue estar en el presentil 99.8 y en muchas otras tareas sabemos que también su desempeño es espectacular, un único modelo, un único sistema. Claro, bajo los estandres de DeepMind en que nivel de AI podríamos catalogar a esta ia. Podríamos preguntarle a los padres de la criatura, podríamos preguntarle a OpenAI que en esto tienen un enfoque mucho más simplista. Ya que ellos definen a la AI como un sistema altamente autónomo que superará los humanos en la mayoría de trabajos económicamente valiosos. Sustituir trabajos económicamente valiosos. ¿Qué tan cerca estamos de esto? Al final hemos visto que los avances en DeepLar ninan aumentado notablemente en los últimos años. Pero sea más realistas, todavía a día de hoy un chat de texto no te va a poner un empaste o va a cuidarte tu jardín o hacerte la declaración de la renta. No. Y aquí entra un juego de diferencia clave cuando hablamos de AI y es si una inteligencia artificial es potencialmente capaz de hacer, pues todas estas tareas frente a una ia que realmente pueda hacerlas. No es lo mismo, porque aún te exista, por ejemplo, potencialmente sabe como conducir y sabe desempeñar un trabajo económicamente viable. Pero claro, si no le damos un coche que conducir no podrá hacer esta tarea. Pues con la ia pasa igual. En esta línea de trabajo de darle infraestructura y capacidad a los modelos para poder extraer todo ese potencial y ejecutar tareas económicamente viable, sabemos que en 2025 hay dos líneas de trabajo muy importante, los agentes autónomos y la robótica. Y es que ya comienzo de 2025 empezamos a ver a los grandes laboratorios presentar agentes autónomos como Operator o Deep Research. Que ya no se limitan sólo a actuar dentro de un chat cuando nosotros la hacemos una petición sino que empiezan a interactuar con el mundo digital. Ya sea para resolver tareas relativamente sencillas, utilizando las interfaces que nosotros utilizamos, pues ratonte, clado y pantalla, o navegar por un largo tiempo para buscar aquellas fuentes de información necesarias para redactarte un informe de calidad profesional. A los modelos del lenguaje ya podemos proponerle tareas, dejar que interactúen independientemente durante un rato y que al rato, con suerte, esa tarea ya esté hecha, más capacidad y más generalidad. Y el equivalente a los agentes autónomos en el mundo físico real pasa por la robótica. Un problema más complejo que depende de mejoras en hardware, baterías y en los algoritmos de aprendizaje automático, para que el robot pueda aprender a moverse, adaptarse y ejecutar con independencia aquellas tareas que le pedamos. Y de nuevo un campo donde cada vez más rápidos se están logrando hitos, que hasta hace no tanto tiempo se veían mucho más lejanos. Y donde ciertamente cada vez vemos más ejemplos que parecen sacados de películas de ciencia ficción. Al final con los agentes autónomos lo que buscamos es darle las herramientas necesarias, la infraestructura, para que puedan desplegar su capacidad de hacer, de ejecutar tareas en el mundo digital. Y de forma equivalente pues buscamos lo mismo con la robótica pero aplicado al mundo físico real. Y esto me hace pensar desde mi punto de vista que la llegada de la agí podría ocurrir en dos tiempos. Que primero y esto es algo que creo que está muy cerca, hablemos de la llegada de la agí en el mundo digital con los agentes autónomos, que se encargarán de realizar a través de internet la mayoría de trabajos digitales, económicamente valiosos. Algo que creo que va a ocurrir en el corto medio plazo y cuya progresión va a ser muy rápida. Y luego en el medio largo plazo la llegada de la agí creo que va a ocurrir más lenta. De forma más paulatina, ha dado los límites, quimpone el mundo físico real. Y por tanto la gran incógnita aquí es Carlos. Cuando va a ocurrir todo esto. En tentarte dar una respuesta correcta aquí pues es muy difícil, muy complicado, porque hay mucha incertidumbre en juego. Pero muchos expertos coinciden sin dar una fecha concreta que esto es algo que con seguridad vamos a experimentar en esta próxima década. Y es que al final las estimaciones con este tipo de tecnologías exponenciales es algo que a nosotros los humanos nos anotá muy bien. Y hay una frase de Ernest Hemingway que se repiten mucho los mundillos de la IA y que captura exactamente esta idea. Gradually, and then, suddenly. Primero gradualmente y luego de repente. Un patrón que en el mundo de la IA vemos ocurrir todo el rato. Primero gradualmente y luego de repente. Primero gradualmente y luego de repente. Primero gradualmente y luego de repente. Y detrás desafrace que captura algo que primero crece lento y luego se dispara, lo que se esconde son los efectos de una curva exponencial. Y como hemos visto la historia de la inteligencia artificial, está repleta de estas curvas. Donde primero nada pasa y de repente cuando te das cuenta todo ha cambiado. Y en el debate de la inteligencia artificial general estas curvas exponenciales entran en juego cuando debatimos cuánto vamos a tardar y llegar a ese futuro. Donde vemos contra ponerse posturas que hablan de un despegue lento donde esta llegada a la IGI sea más paulatina y pausada. Frente la puesta más radical y divertida que sería la del despegue rápido. Donde la llegada a la IGI se viva como un futuro que está ahí al que nos movemos de forma gradual y luego de repente. Y esta curva exponencial de progreso que describiría el despegue rápido se podría explicar por un proceso de auto mejora. Donde la misma tecnología que estamos desarrollando acaba generando efectos que nos permitan llegar más rápido a una siguiente versión más potente de esta tecnología de la que de nuevo podemos aprovecharnos para continuar mejorando. Son estos efectos de auto mejora con retroalimentación positiva lo que podría explicar este despegue rápido. Y mis sensaciones que el punto en el que nos encontramos ahora en estos últimos meses con todos los cambios que estamos viviendo es justo este punto donde la avión empieza a elevar el vuelo. Desde 2023 con los LLMS el uso de la IA en programación ha ido en aumento. Ya que estas herramientas lo que están ofreciendo es la reducción en el coste de producir software. Multiplicando la productividad de todos los programadores del planeta, Mestras Mest, algo que tiene un efecto directo en nuestra economía. Pero es que además aquí ahora entra este concepto de auto mejora y es que delegar cada vez más la programación a la inteligencia artificial no va a permitir poder desarrollar de forma mas agile y más rápida mejor inteligencia artificial. Tener 24 sito un sistema capaz de plantear ideas novedosas, implementarlas, optimizarlas y terar sobre ellas. Es obvio, el siguiente paso de lasías de programación será automatizar todos estos procesos. Algo que ocurrirá pronto cuando los agentes autónomos pueden vayan adquiriendo más y más capacidades. Automatizaremos las fases del proceso del diseño y experimentación de la inteligencia artificial. Sobre esto, Mark Zuckerberg o Sam Almond ya han declarado su intención de diseñar EIA Engineers, ingenieros de inteligencia artificial. Y ya contamos actualmente con benchmarks como MLBinge que buscan medir justo esto, puede una inteligencia artificial hacer las labores de un ingeniero de ia. Y tener inteligencia artificial que abarate el desarrollo de la inteligencia artificial va a permitir que podamos desarrollar mas y mejores modelos para nichos específicos. Nichos que a lo mejor a día de hoy todavía por falta de talento no son rentables pero que si tienes una inteligencia artificial que pueda trabajar en dar solusión a ese problema, pues lo serán. Y así podremos enfocar la inteligencia artificial y todos nuestros recursos computacionales a que la AIA se dedique en cuerpo y alma a la búsqueda de nuevos materiales, a la formulación y demostración de teoremas matemáticos o al diseño de nuevos emiconductores. Y el resultado de esto podrían ser chips más rápidos y eficientes, u optimizaciones matemáticas que aceleren aún más el desarrollo de la AIA, nuevos materiales que podríamos aplicar a mejorar todo nuestro stack tecnológico, pues por ejemplo con baterías que impulsen la transición energética que ya estamos viviendo, y como resultado energía en abundancia que podríamos canjear por más computación de forma sostenible, mejoras que nos acercan a otras mejoras, que nos acercan a otras mejoras en un ciclo que se repite cada vez más rápido. Este camino que acabo de dibujar es uno de los muchos caminos que se están empezando a reproducir ahora mismo, donde los efectos compuestos de toda la mejora que hemos desarrollado en inteligencia artificial en los últimos años empiezan a cobrar sentido. Creo que nunca habíamos tenido antes en el horizonte el potencial de bloquear tantas ramas del árbol tecnológico como tenemos ahora en este presente. Y si bien en la naturaleza no existen realmente curvas exponenciales que crezcan hasta el infinito sino sigmoides que acaban saturando cuando nos encontramos con recursos limitados, aquí tenemos el reto y el desafío de hacerlo bien y de no agotar nuestros recursos por el camino. Y hay entran tanto los recursos naturales que sabemos que este tipo de tecnologías consumen en abundancia como recursos más intangibles como la estabilidad de una sociedad que se va a tener que enfrentar en los próximos años a transformaciones muy radicales. Y ahora que estamos hablando de cambios radicales y de la necesidad de adaptarnos, creo que es importante que hablemos del papel de la formación. En un futuro donde la inteligencia artificial cada vez más va a servir para amplificar nuestras capacidades. En mi caso ha sido estudiando una carrera que me ha permitido aprender todo lo fundamento de programación, de informática, que ahora me sirven para sacarle el máximo partido a todas estas herramientas de ella para programar. Así que si tenemos claro que a día de hoy la inteligencia artificial es un potenciador de nuestras capacidades pues estar actualizado es una necesidad. Y por eso seguir estudiando y aprendiendo a lo largo de la vida es muy importante y si esto además podéis integrarlo en vuestro día a día sin comprometer vuestra carrera profesional, pues mejor que mejor. Y por ello hoy quiero recomendaros la walk, el patrocinador de este vídeo. Quienes cuentan con una formación de calidad donde podrás estudiar dónde, cómo y cuando quieras. Se ignorarios que te restringan en tu jornada diaria y sin necesidad de desplazamiento. Una universidad online que lleva 30 años formando profesionales y que cuenta con titulaciones universitarias de grado, másters, posgrados y también cursos de ámbitos concretos para formarte en temas específicos con poco tiempo. De hecho en mi caso llevo mucho tiempo queriendo estudiar una carrera y por cómo es mejor nada laboral, como es mi trabajo de cambiante, estar viajando todo el rato de un día grabar vídeo, pues se me hace muy complicado y la walk aquí es una opción que me encaja perfectamente. Así que si estás interesado se echarle un vistazo a toda su oferta, dejo abajo un enlace en la descripción. Por concluir, tras todo lo que hemos visto en este vídeo es evidente que nos estamos moviendo cada vez más rápido hacia un futuro donde la inteligencia artificial general será una realidad. Pero al igual que Copernico demostró que nosotros no éramos el centro del universo, creo que es importante resaltar el hecho de lo arbitrario que es colocar en una gráfica en nosotros. Al final hablamos de la inteligencia artificial general como una especie de reflejo de nuestras capacidades, olvidando en muchos casos que estas dos dimensiones pueden seguir creciendo. Bastante, mucho más lejos de donde nos encontramos. Este sería el territorio de la super inteligencia artificial, la ASI, un lugar destinado para aquello sistema de inteligencia artificial que puedan resolver un rango de tareas mayores a las que nosotros podemos resolver e importante con un nivel de desempeño superior al del 100% de los humanos. Inteligencias artificiales superhumanas, tema que reservamos para un próximo vídeo. Checos, chicas, si os ha gustado el vídeo no deje de compartirlo, dejo vuestro like y estamos de vuelta con más contenido aquí en el canal principal. Sabéis que tenemos también el docte subelap para todos los temas de actualidad y este canal va a estar dedicado a temas como este. Más en profundidad vamos a estar hablando de conceptos de fundamentos, análisis, más derayados como este, así que no deje de suscribiros a ambos canales. Checos, chicas, volvemos con más inteligencia artificial aquí en docte subelap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bajar solo la transcripción"
      ],
      "metadata": {
        "id": "SnjPYfMJjWSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api"
      ],
      "metadata": {
        "id": "iSQHhV_kjYkb",
        "outputId": "e7bd57e3-6ade-4c13-c01b-c23e0fe5315a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.1.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.6.15)\n",
            "Downloading youtube_transcript_api-1.1.0-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.7/485.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "# ID del video (por ejemplo: https://www.youtube.com/watch?v=abcd1234 → \"abcd1234\")\n",
        "video_id = \"p_S6NIEfu-U\"\n",
        "\n",
        "# Obtener la transcripción (si está disponible)\n",
        "transcripcion = YouTubeTranscriptApi.get_transcript(video_id, languages=['es'])\n",
        "\n",
        "# Mostrar la transcripción completa (solo texto)\n",
        "texto = \" \".join([segment['text'] for segment in transcripcion])\n",
        "print(texto)"
      ],
      "metadata": {
        "id": "TOCBMkn_jaeg",
        "outputId": "4e68a7a2-fed2-43a1-f471-64d266f08f22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "la Inteligencia artificial cada vez es más potente Y si hace 5 años apenas contábamos solo con sistemas capaces de leer o balbucear textos a día de hoy Contamos con sistemas capaces de resolver problemas de olimpiadas matemáticas de posicionarse en los ranking mundiales de competiciones de programación o creando instantáneamente piezas audiovisuales indiferencia bles de la realidad todos lo estamos sintiendo verdad ese vértigo es es sentimiento de que lo único que podemos tener claro sobre el futuro es que va a ser muy diferente al presente que estamos viviendo ahora que las predicciones de que la ia lo iba a cambiar todo se Están volviendo realidad sentís la agi artif general intellig agi soon ya os adelanto que en 2025 mucho del debate de la Inteligencia artificial se va a centrar justamente en este concepto la Inteligencia artificial general la Ai pero exactamente qué es Cómo se define Y qué tan cerca estamos de conseguirla hoy analizamos por primera vez en este canal y que sirva esto como testimonio de los tiempos que estamos viviendo El concepto de agi el ser humano tiene tendencia a verse como el centro del universo y cuando hablamos de inteligencia no iba a ser menos si viajamos a 1956 en la histórica conferencia de dartmouth donde se forjó el concepto de Inteligencia artificial la propuesta inicial ya indicaba que sería un intento de averiguar Cómo lograr que las máquinas usaran el lenguaje formaran abstracciones y conceptos y resolvieran tipos de problemas que actualmente estaban reservados para los humanos una propuesta muy ambiciosa puesto que para lograr esto se pusieron de plazo dos meses este texto que dio origen al campo de la Inteligencia artificial fue muy premonitorio Estableciendo un objetivo claro máquinas capaces de ser tan inteligente como nosotros pero claro Esto no es un objetivo ambiguo al final una calculadora pues es una máquina que puede hacer cálculos matemáticos a un nivel similar o incluso superior que nosotros con más velocidad y precisión significa eso que una calculadora es una agi no aquí la clave está en la G de agi que nos habla de la inteligencia general y es que recordaréis que ya en 2017 cuando os definí por primera vez en uno de los primeros vídeos del Canal que era la Inteligencia artificial os dije lo siguiente al final es cierto que nosotros los humanos pues no vamos a destacar tanto como una maquinita en tareas concretas pero a somos muy buenos en un Rango amplio de tareas muy variado siendo incluso capaces de aprender nuevas habilidades para adaptarnos y es en esta generalidad en la capacidad de aprender Y ejecutar una gran diversidad de tareas lo que se persigue cuando hablamos de Inteligencia artificial inteligencias artificiales que sean tan capaces en un Rango de tareas tan amplio como nosotros o humanos por lo tanto para empezar a organizar un poco las cosas sí podemos decir que una Inteligencia artificial será más general que otra si es más capaz a la hora de resolver una tarea y además si esa tarea cubre un mayor Rango de habilidades visto Así en estas dos dimensiones podemos decir que gpt 4 es más general que gpt2 por su mejor capacidad de generar texto y porque haciendo esto cubre un Rango mayor de habilidades Traducir código de programación escribir poemas todo esto y claro visto así pues nosotros somos un tipo de inteligencia más general que gpd 4 teniendo este esquema como guía pues podemos ver que el día que la Inteligencia artificial llegue más o menos a este punto es decir mismo desempeño en sus capacidades en un Rango tan amplio como todo lo que nosotros podamos hacer que entonces ahí estaremos hablando de una Magi Y qué tan cerca está la ía de lograr esto pues veamos hemos dicho que una de las dimensiones es su desempeño y a nivel de capacidades desde el Boom del Deep learning y las redes neuronales en 2012 ya sabéis que la Inteligencia artificial no ha parado de mejorar hace menos de 10 años evaluamos a la ia por su capacidad de leer reconocer imágenes o resolver problemas sencillos de matemáticas tareas para las que poco a poco la ía alcanzó nuestro nivel Así que le pusimos tareas más difíciles pruebas de conocimiento general lectura en múltiples idiomas competiciones de matemática Y de nuevo a un ritmo más rápido que antes volvió a alcanzar nuestras capacidades de hecho a día de hoy modelos como gpt 4o clod o gemini se evalúan sobre tareas no para ias sino tareas académicas y profesionales para humanos logrando nuevamente cada vez un mayor desempeño es decir en cuestión de 15 años la í ha pasado de aprender a hablar y escribir a sacarse múltiples carreras universitarias a la vez así que en capacidades pues cada vez nos movemos más rápido en esta dirección y en generalidad pues Mirad aquí es donde creo que está lo más interesante porque de nuevo hace no tanto tiempo los modelos de ia eran sistemas de redes neuronales que se entrenaban para hacer muy bien una única tarea y sí la hacían muy bien bien pero era eso una sola tarea una ia entrenada para hacerte resúmenes de texto pues no era capaz de escribirte bien un poema pero luego llegó esta idea de los modelos fundacionales como los gpt donde ahora un mismo modelo pues te podía ser un resumen Traducir responder preguntas es decir un único modelo resolviendo múltiples tareas inteligencias artificiales más generales pero es que luego a esto le sumamos también la multimodalidad la capacidad de que la ia pueda procesar fuentes de información de diferente naturaleza texto imágenes audio acciones de robots haciendo por tanto a los modelos más Versátiles y capaces de resolver tareas en múltiples dominios modelos más generales y la última tendencia que tenemos que sumar ahora es el actual paradigma del test Time compute donde los modelos pueden dedicar tiempo de computación a pensar más en la solución de un problema planteando opciones y estrategias alternativas y diseñando durante la inferencia soluciones creativas a problemas nuevos demostrando una creatividad nunca antes vista que ahora nos permite utilizar estos modelos Ya entrenados para resolver problemas que antes la ia no podía resolver en cuestión de una década modelos más capaces y más generales y casi parecería que pocos más avances pues se tienen que dar para poder llegar a ese objetivo de la agi dice Sam alm en una de sus últimas declaraciones que están confiados en que saben cómo construir like I think from here to building agi Will Still take a huge amount of work there are some known unknowns but I think basic know what what to do and Take While hard but That's tremendously exar Estando todo esto resuelto pues uno podría pensar que lo más difícil ya queda atrás pero realmente lo más difícil viene ahora y es saber diferenciar Qué hay tanto de Real Y cuánto hay de marketing porque los incentivos para empresas privadas de decir que saben Cómo construir una agi son elevados de existir una tecnología de tal calibre Pues sería de un altísimo valor económico para la empresa que lo posea y siendo así Quién no invertiría en una empresa que dice saber cómo implementarla De hecho hay incluso casos más curiosos en toda esta batalla comercial por la ía general en el acuerdo de Alianza entre Open Ai y Microsoft donde ya sabéis que uno ofrece acceso al otro a grandes cantidades de recursos computacionales Mientras que el otro le da acceso a sus investigaciones y tecnologías más avanzadas pero ah ojito porque no todas las tecnologías desarrolladas por Open Ai van a ser dadas a Microsoft y es que en el acuerdo lo especifican muy bien el acuerdo quedará invalidado si esa tecnología es una agi y claro siendo esto así hay muchos incentivos por parte de muchas empresas por declararse Conquistadores de la la agi lo cual nos obliga a definirlo con un poquito más de exactitud y aquí aparece una de las empresas que fue pionera a la hora de ponerse como objetivo construir una agi en tiempos en los que decir esto en alto era motivo de burla en la academia hablamos por supuesto del laboratorio Deep Mind que en uno de sus papers del año pasado de 2024 definía con la siguiente tabla los diferentes niveles de sistema inteligentes con los que clasificar a una agi Para ello se basaban en estas dos dimensiones que hemos comentado antes la capacidad de la ia a la hora de resolver una tarea medido en este caso por el percentil que ocuparía esa ía frente al resto de la humanidad y luego por su grado de generalidad aquí clasificado entre inteligencias artificiales específicas e inteligencias artificiales generales visto así por ejemplo en el nivel uno pues nos encontramos aquellas ías que tienen capacidades iguales o un poquito mejor que las de un humano no especial realizado es decir aquellas inteligencias artificiales cuyo nivel de desempeño fuera pues el tuyo o el mío para aquellas tareas de las cuales nosotros no somos especialistas Pues yo por ejemplo no sé escribir un haq sé la idea general tres frasecitas pues puedo chapurrear ese sería el nivel uno y lo interesante es que en este nivel es donde aparecían sistemas como chat gpt o gemini catalogadas como ías generales emergentes es decir pueden hacer un amplio Rango de tareas al igual que un humano no especializado pero luego esto continúa con más niveles competente si supera la mitad de la población adulta experto si supera el 90 por virtuoso en el 99% y 100% al nivel superhumano y para cada uno de estos niveles Pues sí tenemos ejemplos de ías estrechas cuyo desempeño se enfoca solo en tareas concretas donde sabemos que a día de hoy Contamos con sistemas que juegan a la ajedrez mejor que humanos o capaces de predecir las formas de la proteína que yo por ejemplo no soy capaz okay sin embargo lo interesante lo encontramos en la otra columna en la de la ia generalista no se ha conseguido no se ha conseguido y no se ha conseguido claro esto de hace un año Pero y si tuviéramos que actualizarla a día de hoy acaso sistemas como chat gpt no son capaces de hacer ahora tareas que lograban hace un año pero a un nivel superior que el de la mitad de la población o incluso mejor que el 90 por de la población a nivel experto de hecho hemos visto que modelos como o3 en competiciones de programación pues consigue estar en el percentil 99,8 y en muchas otras tareas sabemos que también su desempeño es espectacular un único modelo un único sistema claro bajo los estándares de Deep Mind En qué nivel de agi podríamos catalogar a esta illa pues podríamos preguntarle a los padres de la criatura podríamos pregun preguntarle a Open Ai que en esto tienen un enfoque mucho más simplista Ya que ellos definen a la agi como un sistema altamente autónomo que superará a los humanos en la mayoría de trabajos económicamente valiosos HM sustituir trabajos económicamente valiosos qué tan cerca estamos de esto al final hemos visto que los avances en deeplearning han aumentado notablemente en los últimos años pero seamos realistas todavía a día de hoy un chat de texto no te va a poner un empaste o va a cuidarte tu jardín o hacerte la declaración de la renta no y aquí entra en juego una diferencia clave cuando hablamos de Ai y es si una Inteligencia artificial es potencialmente capaz de hacer pues todas estas tareas frente a una ía que realmente pueda hacerlas no es lo mismo porque un taxista por ejemplo potencialmente sabe cómo conducir y sabe desempeñar un trabajo económicamente viable pero claro si no le damos un coche que conducir no podrá hacer esta tarea pues con la ia pasa igual y en esta línea de trabajo de darle infraestructura Y capacidad a los modelos para poder extraer todo ese potencial y ejecutar tareas económicamente viables sabemos que en 2025 hay dos líneas de trabajo muy importante los agentes autónomos y la robótica Y es que ya comienzos de 2025 empezamos a ver a los grandes laboratorios presentar a agentes autónomos como operator o Deep research que ya no no se limitan solo a actuar dentro de un chat cuando nosotros le hacemos una petición sino que empiezan a interactuar con el mundo digital ya sea para resolver tareas relativamente sencillas utilizando las interfaces que nosotros utilizamos pues ratón teclado y pantalla o navegar por un largo tiempo para buscar aquellas fuentes de información necesarias para redactar un informe de calidad profesional a los modelos del lenguaje ya podemos proponerle tareas dejar que interactúen independientemente durante un rato y que al rato con suerte esa tarea ya esté hecha más capacidad y más generalidad y el equivalente a los agentes autónomos en el mundo físico real pasa por la robótica un problema más complejo que depende de mejoras en Hardware baterías y en los algoritmos de aprendizaje automático para que el robot pueda aprender a moverse adaptarse y a ejecutar con Independencia aquellas tareas que le pidamos Y de nuevo un campo donde cada vez más rápido se están logrando hitos que hasta hace no tanto tiempo se veían mucho más lejanos y donde ciertamente cada vez vemos más ejemplos que parecen sacados de películas de ciencia ficción al final con los agentes autónomos lo que buscamos es darle las herramientas necesarias la infraestructura para que puedan desplegar su capacidad de hacer de ejecutar tareas en el mundo digital Y de forma equivalente pues buscamos lo mismo con la robótica pero aplicado al mundo físico real y esto me hace pensar desde mi punto de vista que la llegada de la agi podría ocurrir en dos tiempos que primero y esto es algo que creo que está muy cerca hablemos de la llegada de la Ai en el mundo digital con los agentes autónomos que se encargarán de realizar a través de internet la mayoría de trabajos digitales económicamente valiosos algo que creo que va a ocurrir en el corto medio plazo y cuya progresión va a ser muy rápida y luego en el medio y largo plazo la llegada de la agi creo que va a ocurrir más lenta de forma más paulatina dado los límites que impone el mundo físico real y por tanto la gran incógnita aquí es Carlos cuándo va a ocurrir todo esto intentar dar una respuesta correcta aquí pues es muy difícil muy complicado porque hay mucha incertidumbre en juego pero muchos expertos coinciden Sin dar una fecha concreta que esto es algo que con seguridad vamos a experimentar en esta próxima década Y es que al final hacer estimaciones con este tipo de tecnologías exponenciales es algo que a nosotros otros los humanos no se nos da muy bien y hay una frase de Ernest hemingway que se repiten mucho los mundillos de la ia y que captura exactamente esta idea gradually and then suddenly primero gradualmente y luego de repente un patrón que en el mundo de la ía vemos ocurrir todo el rato primero gradualmente y luego de repente primero gradualmente y luego de repente primero gradualmente y luego de repente y mientras de esa frase que captura algo que primero crece lento y luego se dispara lo que se esconde son los efectos de una curva exponencial y como hemos visto la historia de la Inteligencia artificial está repleta de estas curvas donde primero nada pasa y de repente cuando te das cuenta todo ha cambiado y en el debate de la Inteligencia artificial general estas curvas exponenciales entran en juego cuando debatimos cuánto vamos a tardar en llegar a ese futuro donde vemos contraponerse posturas que hablan de un pegue lento donde esta llegada a la egi sea más paulatina y pausada frente a la apuesta más radical y divertida que sería la del despegue rápido donde la llegada al agi se viva como un futuro que está ahí al que nos movemos de forma gradual y luego de repente y esta curva exponencial de Progreso que describiría El despegue rápido se podría explicar por un proceso de automejora donde la misma tecnología que estamos desarrollando acaba generando efectos que nos permitan llegar más rápido a una siguiente versión más potente de esta tecnología de la que de nuevo podemos aprovecharnos para continuar mejorando son estos efectos de automejora con retroalimentación positiva lo que podría explicar este despegue rápido y mi sensación es que el punto en el que nos encontramos ahora en estos últimos meses con todos los cambios que estamos viviendo es justo este punto donde el avión empieza a Elevar el vuelo desde 2023 con los llms el uso de la ia en programación ha ido en aumento ya que estas herramientas lo que están ofreciendo es la reducción en el coste de producir software multiplicando la productividad de todos los programadores del planeta mes tras mes algo que tiene un efecto directo en nuestra economía pero es que además aquí ahora entra este concepto de automejora Y es que delegar cada vez más la programación a la Inteligencia artificial nos va a permitir poder desarrollar de forma más ágil y más rápida mejor Inteligencia artificial tener 247 un sistema capaz de plantear ideas novedosas implementarlas optimizarlas iterar sobre ellas es obvio el siguiente paso de las Sas de programación será automatizar todos estos procesos algo que ocurrirá pronto cuando los agentes autónomos Pues vayan adquiriendo más y más capacidades automatizar remos las fases del proceso del diseño y experimentación de la Inteligencia artificial sobre esto Mark Zuckerberg o Sam alm ya han declarado su intención de diseñar Ai engineers ingenieros de Inteligencia artificial y ya contamos actualmente con benchmarks como ML bench que buscan medir justo esto puede una Inteligencia artificial hacer las labores de un ingeniero de ia y tener Inteligencia artificial que abarate el desarrollo de la Inteligencia artificial va a permitir que podamos desarrollar más y mejores modelos para nichos específicos nichos que a lo mejor a día de hoy todavía por falta de talento Pues no son rentables pero que si tienes una Inteligencia artificial que pueda trabajar en dar solución a ese problema pues lo serán y así podremos enfocar a la Inteligencia artificial y todos nuestros recursos computacionales a que la ía se dedique en cuerpo y alma a la búsqueda de nuevos materiales a la formulación y demostración de teoremas matemáticos o al diseño de nuevos semiconductores y el resultado de esto pues podrían ser chips más rápidos y eficientes u optimizaciones matemáticas que aceleren aún más el desarrollo de la ia nuevos materiales que podríamos aplicar a mejorar todo nuestro stack tecnológico pues por ejemplo con baterías que impulsen la transición energética que ya estamos viviendo y como resultado energía en abundancia que podríamos canjear por más computación de forma sostenible mejoras que nos acercan a otras mejoras que nos acercan a otras mejoras en un ciclo que se repite cada vez más rápido este camino que acabo de dibujar es uno de los muchos caminos que se están empezando a reproducir ahora mismo donde los efectos compuestos de toda la mejora que hemos desarrollado en Inteligencia artificial en los últimos años empiezan a cobrar sentido Creo que nunca habíamos tenido antes en el Horizonte el potencial de desbloquear tantas ramas del árbol tecnológico como tenemos ahora en este presente y si bien en la naturaleza no existen realmente curvas exponenciales que crezcan hasta el infinito sino sigmoides que acaban saturando cuando nos encontramos con recursos limitados aquí tenemos el reto y el desafío de hacerlo bien y de no agotar nuestros recursos por el camino y ahí entran tanto los recursos naturales que sabemos que este tipo de tecnologías consumen en abundancia como recursos más intangibles como la estabilidad de una sociedad que se va a tener que enfrentar en los próximos años a trans formaciones muy radicales y ahora que estamos hablando de cambios radicales y de la necesidad de adaptarnos creo que es importante que hablemos del papel de la formación en un futuro donde la Inteligencia artificial cada vez más va a servir para amplificar nuestras capacidades en mi caso ha sido estudiando una carrera que me ha permitido aprender todos los fundamentos de programación de informática que ahora me sirven para sacarle el máximo partido a todas estas herramientas de ia para programar Así que si tenemos Claro que a día de hoy la Inteligencia artificial es un potenciador de nuestras capacidades pues estar actualizado es una necesidad y por eso seguir estudiando y Aprendiendo a lo largo de la vida es muy importante y si esto además podéis integrarlo en vuestro día a día sin comprometer vuestra carrera profesional pues mejor que mejor y por ello hoy quiero recomendaros la Wok el patrocinador de este vídeo Quienes cuentan con una formación de calidad donde podrás estudiar Dónde Cómo y cuando quieras sin horarios que te restrinjan en tu jornada diaria y sin necesidad de desplazamientos una universidad online que lleva 30 años formando a profesionales y que cuenta con titulaciones universitarias de grado Masters postgrados y también cursos de ámbitos concretos para formarte en temas específicos con poco tiempo de hecho en mi caso llevo mucho tiempo queriendo estudiar una carrera y por cómo es mi jornada laboral como es mi trabajo de cambiante de estar viajando todo el rato de un día grabar vídeo pues se me hace muy complicado y la Wok aquí es una opción que me encaja perfectamente Así que si estáis interesados echadle un vistazo a toda su oferta dejo abajo un enlace en la descripción por concluir tras todo lo que hemos visto en este vídeo Es evidente que nos estamos moviendo cada vez más rápido hacia un futuro donde la Inteligencia artificial general será una realidad pero al igual que Copérnico demostró que nosotros no éramos el centro del universo creo que es importante Resaltar el hecho de loit que es colocar en una gráfica El nosotros al final hablamos de la Inteligencia artificial general como una especie de reflejo de nuestras capacidades olvidando en muchos casos que estas dos dimensiones pues Pueden seguir creciendo bastante mucho más lejos de donde nos encontramos este sería el territorio de la superinteligencia artificial la asi un lugar destinado para aquellos sistemas de Inteligencia artificial que puedan resolver Pues un Rango de tareas mayores a las que nosotros podemos resolver e importante con un nivel de desempeño superior al del 100% de los humanos inteligencias artificiales superhuman tema que reservamos para un próximo vídeo chicos chicas si os ha gustado el vídeo no dejéis de compartirlo Dejad vuestro like y estamos de vuelta con más contenido aquí en el canal principal sabéis que tenemos también el dots SV lab para todos los temas de actualidad y este canal va a estar dedicado a temas pues como este más en profundidad vamos a estar hablando de conceptos de fundamentos análisis más detallados como este así que no dejéis de suscribiros a ambos canales chicos y chicas volvemos con más Inteligencia artificial aquí en dots suv\n"
          ]
        }
      ]
    }
  ]
}